{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-52260da00c87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m      \u001b[0mgevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mgather_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-52260da00c87>\u001b[0m in \u001b[0;36mgather_html\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m    \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m    \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m    \u001b[0mstat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhtml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"div\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"parsys mainParsys section\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m    \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m    \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"stats_html/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#need to replace to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import gevent\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "category_url_stub = 'http://www.pgatour.com/stats/categories.%s.html'\n",
    "category_labels = ['RPTS_INQ', 'ROTT_INQ', 'RAPP_INQ', 'RARG_INQ', 'RPUT_INQ', 'RSCR_INQ', 'RSTR_INQ', 'RMNY_INQ']\n",
    "pga_tour_base_url = \"http://www.pgatour.com\"\n",
    "url_stub = \"http://www.pgatour.com/stats/stat.%s.%s.html\" #stat id, year\n",
    "\n",
    "def gather_pages(url, filename):\n",
    " print(filename)\n",
    " urllib.urlretrieve(url, filename)\n",
    " \n",
    "def gather_html():\n",
    " stat_ids = []\n",
    " for category in category_labels:\n",
    "     category_url = category_url_stub % (category)\n",
    " page = requests.get(category_url)\n",
    " html = BeautifulSoup(page.text.replace('\\n',''), 'html.parser')\n",
    " for table in html.find_all(\"div\", class_=\"table-content\"):\n",
    "   for link in table.find_all(\"a\"):\n",
    "     stat_ids.append(link['href'].split('.')[1])\n",
    " starting_year = 2015 #page in order to see which years we have info for\n",
    " for stat_id in stat_ids:\n",
    "   url = url_stub % (stat_id, starting_year)\n",
    "   page = requests.get(url)\n",
    "   html = BeautifulSoup(page.text.replace('\\n',''), 'html.parser')\n",
    "   stat = html.find(\"div\", class_=\"parsys mainParsys section\").find('h3').text\n",
    "   print(stat)\n",
    "   directory = \"stats_html/%s\" % stat.replace('/', ' ') #need to replace to avoid\n",
    "   if not os.path.exists(directory):\n",
    "     os.makedirs(directory)\n",
    "   years = []\n",
    "   for option in html.find(\"select\", class_=\"statistics-details-select\").find_all(\"option\"):\n",
    "     year = option['value']\n",
    "     if year not in years:\n",
    "       years.append(year)\n",
    "   url_filenames = []\n",
    "   for year in years:\n",
    "     url = url_stub % (stat_id, year)\n",
    "     filename = \"%s/%s.html\" % (directory, year)\n",
    "     if not os.path.isfile(filename): #this check saves time if you've already downloaded the page\n",
    "       url_filenames.append((url, filename))\n",
    "     jobs = [gevent.spawn(gather_pages, pair[0], pair[1]) for pair in url_filenames]\n",
    "     gevent.joinall(jobs)\n",
    "\n",
    "gather_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
